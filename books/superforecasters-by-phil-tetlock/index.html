<!DOCTYPE html>
<html>
<head>
  <title>Superforecasters by Phil Tetlock | Boris Smus</title>

  <meta charset='utf-8' />
  <meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0' />

  <meta name="description" content="Good vs bad experts is apparently thing. I wondered: was there enough data to really know? What if everyone is a bad forecaster in aggregate? Luckily Tetlock addresses it later.    How to superforecast:      Consider the outside view (eg. base rates)   Consider many perspectives on the same issue (eg. on one hand, on the other hand, on the third hand, on the nth hand).   Fermi problem style breakdown   Might benefit from explicit uncertainty tracking software. It's apparently  a genre .   I'm most interested in  guesstimate    Include opinions of others. They are valuable data.      Also interesting is the personality trait of being open to new experiences. And curiosity in general.    Active open mindedness. Seek out dissenting opinions.    Debaters is an instance of active open mindedness too - AOM    "Beliefs are hypotheses to be tested, not treasures to be guarded"    Interesting idea: adversarial collaboration. For example, Kahneman &amp; Klein, usually at odds with one another, still managed to publish an influential paper: http://www.fiddlemath.net/stuff/conditions-for-intuitive-expertise.pdf    Kahneman sneaking in: suggesting that supreforecasters are better at "internalizing" system 2 thinking via system 1.    Tetlock closes with a summary of the book in the form of ten commandments:      Triage. Focus on questions where extra attention is likely to improve accuracy. Not too hard, not too easy. Weigh the consequences of wasting time on an unpredictable event vs failing to predict a predictable event before deciding whether to invest effort on a problem.   Break seemingly intractable problems into tractable sub-problems ie use Fermi estimates.   Strike the right balance between the inside and outside views.   Strike the right balance between under- and over-reacting to new evidence.   Look for the clashing causal forces at work in each problem. Weigh all the perspectives.   Strive to distinguish as many degrees of doubt as the problem permits, but no more ie get comfortable using fine-grained estimates for fine-grained problems.   Strike the right balance between under- and over-confidence, between prudence and decisiveness.   Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases. Own your failures!   Bring out the best in others and let others bring out the best in you. Team dynamics matter as much as team composition.   Master the error-balancing bicycle. These commandments are not enough - you need deep, deliberative practice.   Don’t treat commandments as commandments.      Overall a great book, but I'm left feeling a bit unsatisfied. Another random thought: everything I've read this year is basically like "foxes &gt;&gt; hedgehogs". But surely there must be some good arguments in defense of hedgehogs." />
  <meta name="author" content="Boris Smus" />
  <link rel="canonical" href="https://smus.com/books/superforecasters-by-phil-tetlock" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Superforecasters by Phil Tetlock" />
  <meta name="twitter:description" content="Good vs bad experts is apparently thing. I wondered: was there enough data to really know? What if everyone is a bad forecaster in aggregate? Luckily Tetlock addresses it later.    How to superforecast:      Consider the outside view (eg. base rates)   Consider many perspectives on the same issue (eg. on one hand, on the other hand, on the third hand, on the nth hand).   Fermi problem style breakdown   Might benefit from explicit uncertainty tracking software. It's apparently  a genre .   I'm most interested in  guesstimate    Include opinions of others. They are valuable data.      Also interesting is the personality trait of being open to new experiences. And curiosity in general.    Active open mindedness. Seek out dissenting opinions.    Debaters is an instance of active open mindedness too - AOM    "Beliefs are hypotheses to be tested, not treasures to be guarded"    Interesting idea: adversarial collaboration. For example, Kahneman &amp; Klein, usually at odds with one another, still managed to publish an influential paper: http://www.fiddlemath.net/stuff/conditions-for-intuitive-expertise.pdf    Kahneman sneaking in: suggesting that supreforecasters are better at "internalizing" system 2 thinking via system 1.    Tetlock closes with a summary of the book in the form of ten commandments:      Triage. Focus on questions where extra attention is likely to improve accuracy. Not too hard, not too easy. Weigh the consequences of wasting time on an unpredictable event vs failing to predict a predictable event before deciding whether to invest effort on a problem.   Break seemingly intractable problems into tractable sub-problems ie use Fermi estimates.   Strike the right balance between the inside and outside views.   Strike the right balance between under- and over-reacting to new evidence.   Look for the clashing causal forces at work in each problem. Weigh all the perspectives.   Strive to distinguish as many degrees of doubt as the problem permits, but no more ie get comfortable using fine-grained estimates for fine-grained problems.   Strike the right balance between under- and over-confidence, between prudence and decisiveness.   Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases. Own your failures!   Bring out the best in others and let others bring out the best in you. Team dynamics matter as much as team composition.   Master the error-balancing bicycle. These commandments are not enough - you need deep, deliberative practice.   Don’t treat commandments as commandments.      Overall a great book, but I'm left feeling a bit unsatisfied. Another random thought: everything I've read this year is basically like "foxes &gt;&gt; hedgehogs". But surely there must be some good arguments in defense of hedgehogs." />

  <!-- Facebook -->
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://smus.com/books/superforecasters-by-phil-tetlock" />
  <meta property="og:title" content="Superforecasters by Phil Tetlock" />
  <meta property="og:description" content="Good vs bad experts is apparently thing. I wondered: was there enough data to really know? What if everyone is a bad forecaster in aggregate? Luckily Tetlock addresses it later.    How to superforecast:      Consider the outside view (eg. base rates)   Consider many perspectives on the same issue (eg. on one hand, on the other hand, on the third hand, on the nth hand).   Fermi problem style breakdown   Might benefit from explicit uncertainty tracking software. It's apparently  a genre .   I'm most interested in  guesstimate    Include opinions of others. They are valuable data.      Also interesting is the personality trait of being open to new experiences. And curiosity in general.    Active open mindedness. Seek out dissenting opinions.    Debaters is an instance of active open mindedness too - AOM    "Beliefs are hypotheses to be tested, not treasures to be guarded"    Interesting idea: adversarial collaboration. For example, Kahneman &amp; Klein, usually at odds with one another, still managed to publish an influential paper: http://www.fiddlemath.net/stuff/conditions-for-intuitive-expertise.pdf    Kahneman sneaking in: suggesting that supreforecasters are better at "internalizing" system 2 thinking via system 1.    Tetlock closes with a summary of the book in the form of ten commandments:      Triage. Focus on questions where extra attention is likely to improve accuracy. Not too hard, not too easy. Weigh the consequences of wasting time on an unpredictable event vs failing to predict a predictable event before deciding whether to invest effort on a problem.   Break seemingly intractable problems into tractable sub-problems ie use Fermi estimates.   Strike the right balance between the inside and outside views.   Strike the right balance between under- and over-reacting to new evidence.   Look for the clashing causal forces at work in each problem. Weigh all the perspectives.   Strive to distinguish as many degrees of doubt as the problem permits, but no more ie get comfortable using fine-grained estimates for fine-grained problems.   Strike the right balance between under- and over-confidence, between prudence and decisiveness.   Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases. Own your failures!   Bring out the best in others and let others bring out the best in you. Team dynamics matter as much as team composition.   Master the error-balancing bicycle. These commandments are not enough - you need deep, deliberative practice.   Don’t treat commandments as commandments.      Overall a great book, but I'm left feeling a bit unsatisfied. Another random thought: everything I've read this year is basically like "foxes &gt;&gt; hedgehogs". But surely there must be some good arguments in defense of hedgehogs." />


  <!-- Icons -->
  <link rel="icon" type="image/x-icon" href="/static/icons/favicon.ico" />
  <link rel="apple-touch-icon" href="/static/icons/apple-touch-icon.png">

  <!-- Styles -->
  <link
  href='//fonts.googleapis.com/css?family=Roboto+Condensed:300|Open+Sans+Condensed:700|Source+Serif+Pro:400,700|Inconsolata' rel='stylesheet' type='text/css'>
  <link rel='stylesheet' href='/static/css/style.css'>
  <link rel='stylesheet' href='/static/css/syntax-highlight.css'>

  <!-- Feed -->
  <link href="//feeds.feedburner.com/smuscom" rel="alternate" title="Boris Smus" type="application/atom+xml"/>
</head>
<body>
<header>
  <div id='title'>
    <h1><a href='/'>Boris Smus</a></h1>
    <h2>interaction engineering</h2>
  </div>
  <nav role='navigation'>
    <a href='/about/' >About</a>
    <a href='/blog/' >Blog</a>
    <a href='/clippings/' >Clippings</a>
  </nav>
</header>

<section id='main'>
  <article>
    <a href='/books/superforecasters-by-phil-tetlock'><h1 class='title'>Superforecasters by Phil Tetlock</h1></a>
    <div class='body'>
      <p>Good vs bad experts is apparently thing. I wondered: was there enough data to
really know? What if everyone is a bad forecaster in aggregate? Luckily Tetlock
addresses it later.</p>

<p>How to superforecast:</p>

<ul>
<li>Consider the outside view (eg. base rates)</li>
<li>Consider many perspectives on the same issue (eg. on one hand, on the other hand, on the third hand, on the nth hand).</li>
<li>Fermi problem style breakdown</li>
<li>Might benefit from explicit uncertainty tracking software. It's apparently <a href="https://en.wikipedia.org/wiki/List_of_uncertainty_propagation_software">a
genre</a>.</li>
<li>I'm most interested in <a href="https://www.getguesstimate.com/scratchpad">guesstimate</a></li>
<li>Include opinions of others. They are valuable data.</li>
</ul>

<p>Also interesting is the personality trait of being open to new experiences. And
curiosity in general.</p>

<p>Active open mindedness. Seek out dissenting opinions.</p>

<p>Debaters is an instance of active open mindedness too - AOM</p>

<p>"Beliefs are hypotheses to be tested, not treasures to be guarded"</p>

<p>Interesting idea: adversarial collaboration. For example, Kahneman &amp; Klein, usually at odds with one another, still managed to publish an influential paper: http://www.fiddlemath.net/stuff/conditions-for-intuitive-expertise.pdf</p>

<p>Kahneman sneaking in: suggesting that supreforecasters are better at "internalizing" system 2 thinking via system 1.</p>

<p>Tetlock closes with a summary of the book in the form of ten commandments:</p>

<ol>
<li>Triage. Focus on questions where extra attention is likely to improve accuracy. Not too hard, not too easy. Weigh the consequences of wasting time on an unpredictable event vs failing to predict a predictable event before deciding whether to invest effort on a problem.</li>
<li>Break seemingly intractable problems into tractable sub-problems ie use Fermi estimates.</li>
<li>Strike the right balance between the inside and outside views.</li>
<li>Strike the right balance between under- and over-reacting to new evidence.</li>
<li>Look for the clashing causal forces at work in each problem. Weigh all the perspectives.</li>
<li>Strive to distinguish as many degrees of doubt as the problem permits, but no more ie get comfortable using fine-grained estimates for fine-grained problems.</li>
<li>Strike the right balance between under- and over-confidence, between prudence and decisiveness.</li>
<li>Look for the errors behind your mistakes but beware of rearview-mirror hindsight biases. Own your failures!</li>
<li>Bring out the best in others and let others bring out the best in you. Team dynamics matter as much as team composition.</li>
<li>Master the error-balancing bicycle. These commandments are not enough - you need deep, deliberative practice.</li>
<li>Don’t treat commandments as commandments.</li>
</ol>

<p>Overall a great book, but I'm left feeling a bit unsatisfied. Another random
thought: everything I've read this year is basically like "foxes &gt;&gt; hedgehogs".
But surely there must be some good arguments in defense of hedgehogs.</p>

    </div>
    <div class='subfooter'>
      <div class='tombstone'>▪</div>
      <time class='published'>January 2017</time>
    </div>
  </article>
</section>


<footer>
  <div>
    © Copyright 2005–2019 Boris Smus.
  </div>
  <nav role="footer">
    <a href='//feeds.feedburner.com/smuscom'>RSS</a>
  </nav>
</footer>

<!-- Misc scripts: syntax highlighting, analytics, stats. -->
<script src="/static/js/highlight.pack.js"></script>
<script>
  // Syntax highlighting for code.
  hljs.tabReplace = '  ';
  hljs.initHighlightingOnLoad();
</script>
<script>
  // Google Analytics.
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-17930798-22', 'smus.com');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');
</script>
<script src="/lightning_error.js"></script>

</body>
</html>