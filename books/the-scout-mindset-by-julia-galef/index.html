<!DOCTYPE html>
<html>
<head>
  <title>The Scout Mindset by Julia Galef | Boris Smus</title>

  <meta charset='utf-8' />
  <meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0' />

  <meta name="description" content="It's been years since I would have said that I aspire to be a rationalist. But I've been swimming in rationality circles for long enough that some of the arguments and ideas in the book are somewhat trite. But I have enjoyed Julia’s podcast for her crispness of thought, ability to popularize, and pleasant voice. I'd recommend this book for someone unfamiliar with modern rationalism that's looking to get their feet wet. It's definitely a more coherent and less overwhelming starting point than lesswrong.    I was looking forward to the takedown of  Gerd Gigerenzer on Gut Feelings , who’s ideas I am sympathetic to.      Soldier mindset  we tend to defend our beliefs against any evidence or arguments that might threaten them. Reasoning in the English language is often described through militaristic metaphors. We try to “shore up” our beliefs, “support them” and “buttress them” as if they’re fortresses. We try to “shoot down” opposing arguments and we try to “poke holes” in the other side.     Scout mindset  The scout’s job is not to attack or defend; it’s to understand. The scout is the one going out, mapping the terrain, identifying potential obstacles. Above all, the scout wants to know what’s really out there as accurately as possible.    Julia argues that scout mindset is always better than soldier mindset. There are some parallels to hedgehogs (Soldiers) and foxes (Scouts) too, as in  The Hedgehog and the Fox by Isaiah Berlin . There are also echoes of System 1 (Soldier) and System 2 (Scout) ideas from  Thinking Fast and Slow by Kahneman and Tversky .    Rational irrationality    Sometimes it's rational to be irrational. For example, you your outcomes as a start-up founder might be better if you have irrational belief in yourself (IS). This can be described as "rational irrationality", which is paradoxical. My prior is that this is well warranted sometimes.     Galef diffuses this paradox and explains what's going on clearly and succinctly. What's happening is that two meanings of rationality are being used:       Instrumental rationality involves the pursuit of a particular end goal, by any means necessary.   Epistemic rationality involves achieving accurate beliefs about the world.      So, to rephrase the paradox is to diffuse it: it may be  instrumentally  rational to be  epistemically  irrational. This is highly related to  Information Hazards .    Always strive for epistemic rationality    Galef argues the "тайное становятся явным" idea, something  I grew up with . Lying to yourself has the same downsides as other social lies that beget more lies. The cascade of muddled thinking proceeds with potentially very long delays and unpredictable outcomes. This is a good argument.    Elon Musk assigned a 10% chance of success to his ventures Space X and Tesla, but decided it was worth trying anyway. Mainly because of the cool factor and his ideological considerations. Green energy!! Electric cars!! Also, space!! But also, rationally speaking, the expected outcome was still high, since the impact of being successful was potentially so great. This resonates with me too, and part of why I think it's worth starting an early stage company one day.    But I still struggle with the absolutist framing that Galef presents. Surely there are situations where you would rather not have maximum rationality? Perhaps actual Infohazards? Or information that would best not be known to you. For example, if you somehow knew exactly how long you would live, it's easy to imagine negative second order effects.    Thought experiments for clearer thinking    Sometimes, if you're about to make a difficult decision, Galef suggests trying one of these thought experiments:       The double standard test . Are you judging one individual or group by a standard that is different from other individuals or groups?    The outsider test : how would you evaluate this situation if it wasn’t your situation?    The conformity test . If other people no longer held the view, would you no longer hold it?    The selective skeptic test . If this evidence supported the other side, how credible would you judge it to be?    Status quo bias test . If your current situation was not the status quo, would you actively choose it?      I suspect the hardest part about Galef's advice is being sufficiently mindful to decide that now is a good time to try.    The idea of calibrated bets is a great one that I've incorporated into my New Years routine. I set predictions for a year ahead on all fronts (SSC, AK inspired) and then see how well calibrated I am.     However generating probabilities for predictions is always tricky. Galef also introduces a technique for called the  equivalent bet test , which she attributes to Douglas Hubbard. The way it works is to compare the issue at hand to a simpler scenario where you randomly draw balls from a jar. One of N balls in the jar is black, and the rest are white. You play with which N would feel right so that both bets yield the same winnings.    Celebrity calibration    I love that Galef picks on Spock, who is often considered a model of rationality. By showing how poorly calibrated he is, she also dispels the idea that being rational means being robotic and failing to understand humans.     In spirit of Spock’s poor calibration, what can we say about Elon Musk's calibration? He gave 10% chance of success to two of his successful companies!    Epistemic vs. social confidence     Social confidence vs. epistemic confidence       Soldier as press secretary: extremely high social confidence, and artificially inflated, unawarranted epistemic confidence.   Scout as board of directors: calibrated epistemic confidence. Knowing what is really true is extremely important.      Her example of Vitalik Buterin is maybe slightly unfortunate. He seems really smart, and appears to be well calibrated epistemically. But he is too dorky to be a paragon of social confidence, in my opinion.    Keep your identity...?    Julia Galef and Paul Graham are overly bearish on identity. But identity is what makes you who you are. By rooting it out you demolish your own uniqueness, traditions, original insights. In this sense I am in favor of intersectionality, but broadly construed. Diversity (see  Measuring non-woke diversity broadly ) not of skin color and gender but of substantive and nuanced things like having been homeschooled, or being a practicing orthodox Christian or believing in Gaia theory or the fact that you raised three children on a 30’ sailboat circumnavigating the globe. Maybe you are super old and survived the Leningrad blockade. Maybe you grew up in desperate poverty. Or even, that you grew up as the son of a Saudi Prince. These things will give you a different perspective on life, and are genuinely valuable to bring to the table.    Great. Reminder. About. Righteous. Sentences. Produced. By. Emphatic. Use. Of. Periods.     I 👋 Should 👋 Use 👋 This 👋 Trick 👋 Way 👋 More 👋 Often." />
  <meta name="author" content="Boris Smus" />
  <link rel="canonical" href="https://smus.com/books/the-scout-mindset-by-julia-galef/" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="The Scout Mindset by Julia Galef" />
  <meta name="twitter:description" content="It's been years since I would have said that I aspire to be a rationalist. But I've been swimming in rationality circles for long enough that some of the arguments and ideas in the book are somewhat trite. But I have enjoyed Julia’s podcast for her crispness of thought, ability to popularize, and pleasant voice. I'd recommend this book for someone unfamiliar with modern rationalism that's looking to get their feet wet. It's definitely a more coherent and less overwhelming starting point than lesswrong.    I was looking forward to the takedown of  Gerd Gigerenzer on Gut Feelings , who’s ideas I am sympathetic to.      Soldier mindset  we tend to defend our beliefs against any evidence or arguments that might threaten them. Reasoning in the English language is often described through militaristic metaphors. We try to “shore up” our beliefs, “support them” and “buttress them” as if they’re fortresses. We try to “shoot down” opposing arguments and we try to “poke holes” in the other side.     Scout mindset  The scout’s job is not to attack or defend; it’s to understand. The scout is the one going out, mapping the terrain, identifying potential obstacles. Above all, the scout wants to know what’s really out there as accurately as possible.    Julia argues that scout mindset is always better than soldier mindset. There are some parallels to hedgehogs (Soldiers) and foxes (Scouts) too, as in  The Hedgehog and the Fox by Isaiah Berlin . There are also echoes of System 1 (Soldier) and System 2 (Scout) ideas from  Thinking Fast and Slow by Kahneman and Tversky .    Rational irrationality    Sometimes it's rational to be irrational. For example, you your outcomes as a start-up founder might be better if you have irrational belief in yourself (IS). This can be described as "rational irrationality", which is paradoxical. My prior is that this is well warranted sometimes.     Galef diffuses this paradox and explains what's going on clearly and succinctly. What's happening is that two meanings of rationality are being used:       Instrumental rationality involves the pursuit of a particular end goal, by any means necessary.   Epistemic rationality involves achieving accurate beliefs about the world.      So, to rephrase the paradox is to diffuse it: it may be  instrumentally  rational to be  epistemically  irrational. This is highly related to  Information Hazards .    Always strive for epistemic rationality    Galef argues the "тайное становятся явным" idea, something  I grew up with . Lying to yourself has the same downsides as other social lies that beget more lies. The cascade of muddled thinking proceeds with potentially very long delays and unpredictable outcomes. This is a good argument.    Elon Musk assigned a 10% chance of success to his ventures Space X and Tesla, but decided it was worth trying anyway. Mainly because of the cool factor and his ideological considerations. Green energy!! Electric cars!! Also, space!! But also, rationally speaking, the expected outcome was still high, since the impact of being successful was potentially so great. This resonates with me too, and part of why I think it's worth starting an early stage company one day.    But I still struggle with the absolutist framing that Galef presents. Surely there are situations where you would rather not have maximum rationality? Perhaps actual Infohazards? Or information that would best not be known to you. For example, if you somehow knew exactly how long you would live, it's easy to imagine negative second order effects.    Thought experiments for clearer thinking    Sometimes, if you're about to make a difficult decision, Galef suggests trying one of these thought experiments:       The double standard test . Are you judging one individual or group by a standard that is different from other individuals or groups?    The outsider test : how would you evaluate this situation if it wasn’t your situation?    The conformity test . If other people no longer held the view, would you no longer hold it?    The selective skeptic test . If this evidence supported the other side, how credible would you judge it to be?    Status quo bias test . If your current situation was not the status quo, would you actively choose it?      I suspect the hardest part about Galef's advice is being sufficiently mindful to decide that now is a good time to try.    The idea of calibrated bets is a great one that I've incorporated into my New Years routine. I set predictions for a year ahead on all fronts (SSC, AK inspired) and then see how well calibrated I am.     However generating probabilities for predictions is always tricky. Galef also introduces a technique for called the  equivalent bet test , which she attributes to Douglas Hubbard. The way it works is to compare the issue at hand to a simpler scenario where you randomly draw balls from a jar. One of N balls in the jar is black, and the rest are white. You play with which N would feel right so that both bets yield the same winnings.    Celebrity calibration    I love that Galef picks on Spock, who is often considered a model of rationality. By showing how poorly calibrated he is, she also dispels the idea that being rational means being robotic and failing to understand humans.     In spirit of Spock’s poor calibration, what can we say about Elon Musk's calibration? He gave 10% chance of success to two of his successful companies!    Epistemic vs. social confidence     Social confidence vs. epistemic confidence       Soldier as press secretary: extremely high social confidence, and artificially inflated, unawarranted epistemic confidence.   Scout as board of directors: calibrated epistemic confidence. Knowing what is really true is extremely important.      Her example of Vitalik Buterin is maybe slightly unfortunate. He seems really smart, and appears to be well calibrated epistemically. But he is too dorky to be a paragon of social confidence, in my opinion.    Keep your identity...?    Julia Galef and Paul Graham are overly bearish on identity. But identity is what makes you who you are. By rooting it out you demolish your own uniqueness, traditions, original insights. In this sense I am in favor of intersectionality, but broadly construed. Diversity (see  Measuring non-woke diversity broadly ) not of skin color and gender but of substantive and nuanced things like having been homeschooled, or being a practicing orthodox Christian or believing in Gaia theory or the fact that you raised three children on a 30’ sailboat circumnavigating the globe. Maybe you are super old and survived the Leningrad blockade. Maybe you grew up in desperate poverty. Or even, that you grew up as the son of a Saudi Prince. These things will give you a different perspective on life, and are genuinely valuable to bring to the table.    Great. Reminder. About. Righteous. Sentences. Produced. By. Emphatic. Use. Of. Periods.     I 👋 Should 👋 Use 👋 This 👋 Trick 👋 Way 👋 More 👋 Often." />

  <!-- Facebook -->
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://smus.com/books/the-scout-mindset-by-julia-galef/" />
  <meta property="og:title" content="The Scout Mindset by Julia Galef" />
  <meta property="og:description" content="It's been years since I would have said that I aspire to be a rationalist. But I've been swimming in rationality circles for long enough that some of the arguments and ideas in the book are somewhat trite. But I have enjoyed Julia’s podcast for her crispness of thought, ability to popularize, and pleasant voice. I'd recommend this book for someone unfamiliar with modern rationalism that's looking to get their feet wet. It's definitely a more coherent and less overwhelming starting point than lesswrong.    I was looking forward to the takedown of  Gerd Gigerenzer on Gut Feelings , who’s ideas I am sympathetic to.      Soldier mindset  we tend to defend our beliefs against any evidence or arguments that might threaten them. Reasoning in the English language is often described through militaristic metaphors. We try to “shore up” our beliefs, “support them” and “buttress them” as if they’re fortresses. We try to “shoot down” opposing arguments and we try to “poke holes” in the other side.     Scout mindset  The scout’s job is not to attack or defend; it’s to understand. The scout is the one going out, mapping the terrain, identifying potential obstacles. Above all, the scout wants to know what’s really out there as accurately as possible.    Julia argues that scout mindset is always better than soldier mindset. There are some parallels to hedgehogs (Soldiers) and foxes (Scouts) too, as in  The Hedgehog and the Fox by Isaiah Berlin . There are also echoes of System 1 (Soldier) and System 2 (Scout) ideas from  Thinking Fast and Slow by Kahneman and Tversky .    Rational irrationality    Sometimes it's rational to be irrational. For example, you your outcomes as a start-up founder might be better if you have irrational belief in yourself (IS). This can be described as "rational irrationality", which is paradoxical. My prior is that this is well warranted sometimes.     Galef diffuses this paradox and explains what's going on clearly and succinctly. What's happening is that two meanings of rationality are being used:       Instrumental rationality involves the pursuit of a particular end goal, by any means necessary.   Epistemic rationality involves achieving accurate beliefs about the world.      So, to rephrase the paradox is to diffuse it: it may be  instrumentally  rational to be  epistemically  irrational. This is highly related to  Information Hazards .    Always strive for epistemic rationality    Galef argues the "тайное становятся явным" idea, something  I grew up with . Lying to yourself has the same downsides as other social lies that beget more lies. The cascade of muddled thinking proceeds with potentially very long delays and unpredictable outcomes. This is a good argument.    Elon Musk assigned a 10% chance of success to his ventures Space X and Tesla, but decided it was worth trying anyway. Mainly because of the cool factor and his ideological considerations. Green energy!! Electric cars!! Also, space!! But also, rationally speaking, the expected outcome was still high, since the impact of being successful was potentially so great. This resonates with me too, and part of why I think it's worth starting an early stage company one day.    But I still struggle with the absolutist framing that Galef presents. Surely there are situations where you would rather not have maximum rationality? Perhaps actual Infohazards? Or information that would best not be known to you. For example, if you somehow knew exactly how long you would live, it's easy to imagine negative second order effects.    Thought experiments for clearer thinking    Sometimes, if you're about to make a difficult decision, Galef suggests trying one of these thought experiments:       The double standard test . Are you judging one individual or group by a standard that is different from other individuals or groups?    The outsider test : how would you evaluate this situation if it wasn’t your situation?    The conformity test . If other people no longer held the view, would you no longer hold it?    The selective skeptic test . If this evidence supported the other side, how credible would you judge it to be?    Status quo bias test . If your current situation was not the status quo, would you actively choose it?      I suspect the hardest part about Galef's advice is being sufficiently mindful to decide that now is a good time to try.    The idea of calibrated bets is a great one that I've incorporated into my New Years routine. I set predictions for a year ahead on all fronts (SSC, AK inspired) and then see how well calibrated I am.     However generating probabilities for predictions is always tricky. Galef also introduces a technique for called the  equivalent bet test , which she attributes to Douglas Hubbard. The way it works is to compare the issue at hand to a simpler scenario where you randomly draw balls from a jar. One of N balls in the jar is black, and the rest are white. You play with which N would feel right so that both bets yield the same winnings.    Celebrity calibration    I love that Galef picks on Spock, who is often considered a model of rationality. By showing how poorly calibrated he is, she also dispels the idea that being rational means being robotic and failing to understand humans.     In spirit of Spock’s poor calibration, what can we say about Elon Musk's calibration? He gave 10% chance of success to two of his successful companies!    Epistemic vs. social confidence     Social confidence vs. epistemic confidence       Soldier as press secretary: extremely high social confidence, and artificially inflated, unawarranted epistemic confidence.   Scout as board of directors: calibrated epistemic confidence. Knowing what is really true is extremely important.      Her example of Vitalik Buterin is maybe slightly unfortunate. He seems really smart, and appears to be well calibrated epistemically. But he is too dorky to be a paragon of social confidence, in my opinion.    Keep your identity...?    Julia Galef and Paul Graham are overly bearish on identity. But identity is what makes you who you are. By rooting it out you demolish your own uniqueness, traditions, original insights. In this sense I am in favor of intersectionality, but broadly construed. Diversity (see  Measuring non-woke diversity broadly ) not of skin color and gender but of substantive and nuanced things like having been homeschooled, or being a practicing orthodox Christian or believing in Gaia theory or the fact that you raised three children on a 30’ sailboat circumnavigating the globe. Maybe you are super old and survived the Leningrad blockade. Maybe you grew up in desperate poverty. Or even, that you grew up as the son of a Saudi Prince. These things will give you a different perspective on life, and are genuinely valuable to bring to the table.    Great. Reminder. About. Righteous. Sentences. Produced. By. Emphatic. Use. Of. Periods.     I 👋 Should 👋 Use 👋 This 👋 Trick 👋 Way 👋 More 👋 Often." />

  <!-- Coil monetization experiment: https://coil.com/settings/monetize -->
  <meta name="monetization" content="$ilp.uphold.com/4Fnyw8KLaPZG">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png">
  <link rel="manifest" href="/static/icons/site.webmanifest">

  <!-- Styles -->
  <link
  href='//fonts.googleapis.com/css?family=Roboto+Condensed:300|Open+Sans+Condensed:700|Source+Serif+Pro:400,700|Inconsolata' rel='stylesheet' type='text/css'>
  <link rel='stylesheet' href='/static/css/style.css'>
  <link rel='stylesheet' href='/static/css/syntax-highlight.css'>

  <!-- Feed -->
  <link href="https://smus.com/atom.xml" rel="alternate" title="Boris Smus" type="application/atom+xml"/>
</head>
<body>
<header>
  <div id='title'>
    <h1><a href='/'>Boris Smus</a></h1>
    <h2>interaction engineering</h2>
  </div>
  <nav role='navigation'>
    <a href='/about/' >About</a>
    <a href='/blog/' >Blog</a>
    <a href='/clippings/' >Clippings</a>
  </nav>
</header>

<section id='main'>
  <article>
    <a href='/books/the-scout-mindset-by-julia-galef'><h1 class='title'>The Scout Mindset by Julia Galef</h1></a>
    
    <img class="book-cover" src="/assets/book-covers/scout-mindset.jpg"/>
    
    <div class='body'>
      <p>It's been years since I would have said that I aspire to be a rationalist. But I've been swimming in rationality circles for long enough that some of the arguments and ideas in the book are somewhat trite. But I have enjoyed Julia’s podcast for her crispness of thought, ability to popularize, and pleasant voice. I'd recommend this book for someone unfamiliar with modern rationalism that's looking to get their feet wet. It's definitely a more coherent and less overwhelming starting point than lesswrong.</p>

<p>I was looking forward to the takedown of <a class="wiki" href="https://z3.ca/Gerd_Gigerenzer_on_Gut_Feelings">Gerd Gigerenzer on Gut Feelings</a>, who’s ideas I am sympathetic to. </p>

<p><strong>Soldier mindset</strong> we tend to defend our beliefs against any evidence or arguments that might threaten them. Reasoning in the English language is often described through militaristic metaphors. We try to “shore up” our beliefs, “support them” and “buttress them” as if they’re fortresses. We try to “shoot down” opposing arguments and we try to “poke holes” in the other side.</p>

<p><strong>Scout mindset</strong> The scout’s job is not to attack or defend; it’s to understand. The scout is the one going out, mapping the terrain, identifying potential obstacles. Above all, the scout wants to know what’s really out there as accurately as possible.</p>

<p>Julia argues that scout mindset is always better than soldier mindset. There are some parallels to hedgehogs (Soldiers) and foxes (Scouts) too, as in <a class="wiki" href="https://z3.ca/The_Hedgehog_and_the_Fox_by_Isaiah_Berlin">The Hedgehog and the Fox by Isaiah Berlin</a>. There are also echoes of System 1 (Soldier) and System 2 (Scout) ideas from <a class="wiki" href="https://z3.ca/Thinking_Fast_and_Slow_by_Kahneman_and_Tversky">Thinking Fast and Slow by Kahneman and Tversky</a>.</p>

<h1>Rational irrationality</h1>

<p>Sometimes it's rational to be irrational. For example, you your outcomes as a start-up founder might be better if you have irrational belief in yourself (IS). This can be described as "rational irrationality", which is paradoxical. My prior is that this is well warranted sometimes. </p>

<p>Galef diffuses this paradox and explains what's going on clearly and succinctly. What's happening is that two meanings of rationality are being used: </p>

<ul>
<li>Instrumental rationality involves the pursuit of a particular end goal, by any means necessary.</li>
<li>Epistemic rationality involves achieving accurate beliefs about the world.</li>
</ul>

<p>So, to rephrase the paradox is to diffuse it: it may be <strong>instrumentally</strong> rational to be <strong>epistemically</strong> irrational. This is highly related to <a class="wiki" href="https://z3.ca/Information_Hazards">Information Hazards</a>.</p>

<h1>Always strive for epistemic rationality</h1>

<p>Galef argues the "тайное становятся явным" idea, something <a href="https://vseskazki.su/dragunskii-deniskiny-rasskazy/tajnoe-stanovitsya-yavnym.html">I grew up with</a>. Lying to yourself has the same downsides as other social lies that beget more lies. The cascade of muddled thinking proceeds with potentially very long delays and unpredictable outcomes. This is a good argument.</p>

<p>Elon Musk assigned a 10% chance of success to his ventures Space X and Tesla, but decided it was worth trying anyway. Mainly because of the cool factor and his ideological considerations. Green energy!! Electric cars!! Also, space!! But also, rationally speaking, the expected outcome was still high, since the impact of being successful was potentially so great. This resonates with me too, and part of why I think it's worth starting an early stage company one day.</p>

<p>But I still struggle with the absolutist framing that Galef presents. Surely there are situations where you would rather not have maximum rationality? Perhaps actual Infohazards? Or information that would best not be known to you. For example, if you somehow knew exactly how long you would live, it's easy to imagine negative second order effects.</p>

<h1>Thought experiments for clearer thinking</h1>

<p>Sometimes, if you're about to make a difficult decision, Galef suggests trying one of these thought experiments:</p>

<ul>
<li><strong>The double standard test</strong>. Are you judging one individual or group by a standard that is different from other individuals or groups?</li>
<li><strong>The outsider test</strong>: how would you evaluate this situation if it wasn’t your situation?</li>
<li><strong>The conformity test</strong>. If other people no longer held the view, would you no longer hold it?</li>
<li><strong>The selective skeptic test</strong>. If this evidence supported the other side, how credible would you judge it to be?</li>
<li><strong>Status quo bias test</strong>. If your current situation was not the status quo, would you actively choose it?</li>
</ul>

<p>I suspect the hardest part about Galef's advice is being sufficiently mindful to decide that now is a good time to try.</p>

<p>The idea of calibrated bets is a great one that I've incorporated into my New Years routine. I set predictions for a year ahead on all fronts (SSC, AK inspired) and then see how well calibrated I am. </p>

<p>However generating probabilities for predictions is always tricky. Galef also introduces a technique for called the <strong>equivalent bet test</strong>, which she attributes to Douglas Hubbard. The way it works is to compare the issue at hand to a simpler scenario where you randomly draw balls from a jar. One of N balls in the jar is black, and the rest are white. You play with which N would feel right so that both bets yield the same winnings.</p>

<h1>Celebrity calibration</h1>

<p>I love that Galef picks on Spock, who is often considered a model of rationality. By showing how poorly calibrated he is, she also dispels the idea that being rational means being robotic and failing to understand humans. </p>

<p>In spirit of Spock’s poor calibration, what can we say about Elon Musk's calibration? He gave 10% chance of success to two of his successful companies!</p>

<h1>Epistemic vs. social confidence</h1>

<p><a class="wiki" href="https://z3.ca/Social_confidence_vs._epistemic_confidence">Social confidence vs. epistemic confidence</a></p>

<ul>
<li>Soldier as press secretary: extremely high social confidence, and artificially
inflated, unawarranted epistemic confidence.</li>
<li>Scout as board of directors: calibrated epistemic confidence. Knowing what is
really true is extremely important.</li>
</ul>

<p>Her example of Vitalik Buterin is maybe slightly unfortunate. He seems really smart, and appears to be well calibrated epistemically. But he is too dorky to be a paragon of social confidence, in my opinion.</p>

<h1>Keep your identity...?</h1>

<p>Julia Galef and Paul Graham are overly bearish on identity. But identity is what makes you who you are. By rooting it out you demolish your own uniqueness, traditions, original insights. In this sense I am in favor of intersectionality, but broadly construed. Diversity (see <a class="wiki" href="https://z3.ca/Measuring_non-woke_diversity_broadly">Measuring non-woke diversity broadly</a>) not of skin color and gender but of substantive and nuanced things like having been homeschooled, or being a practicing orthodox Christian or believing in Gaia theory or the fact that you raised three children on a 30’ sailboat circumnavigating the globe. Maybe you are super old and survived the Leningrad blockade. Maybe you grew up in desperate poverty. Or even, that you grew up as the son of a Saudi Prince. These things will give you a different perspective on life, and are genuinely valuable to bring to the table.</p>

<p>Great. Reminder. About. Righteous. Sentences. Produced. By. Emphatic. Use. Of. Periods. </p>

<p>I 👋 Should 👋 Use 👋 This 👋 Trick 👋 Way 👋 More 👋 Often.</p>

    </div>
    <div class='subfooter'>
      <div class='tombstone'>▪</div>
      <time class='published'>October 2021</time>
    </div>
  </article>
</section>


<footer>
  <div>
    © Copyright 2005–2022 Boris Smus.
  </div>
  <nav role="footer">
    <a href='https://smus.com/atom.xml'>RSS</a>

    <!-- Mastodon verification -->
    <a rel="me" href="https://mastodon.social/@borismus" style="display: none">Mastodon</a>
  </nav>
</footer>

<!-- Misc scripts: syntax highlighting, analytics, stats. -->
<script src="/static/js/highlight.pack.js"></script>
<script>
  // Syntax highlighting for code.
  hljs.tabReplace = '  ';
  hljs.initHighlightingOnLoad();
</script>
<script>
  // Google Analytics.
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-17930798-22', 'smus.com');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');
</script>
<script src="/lightning_error.js"></script>

</body>
</html>