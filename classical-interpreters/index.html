<!DOCTYPE html>
<html>
<head>
  <title>Comparing classical music interpretations | Boris Smus</title>

  <meta charset='utf-8' />
  <meta name='viewport' content='width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0' />

  <meta name="description" content="I built an audio player to easily compare multiple interpretations of the same piece. Here's an interactive  demo , and a video to give you a sense of how it works:" />
  <meta name="author" content="Boris Smus" />
  <link rel="canonical" href="https://smus.com/classical-interpreters/" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Comparing classical music interpretations" />
  <meta name="twitter:description" content="I built an audio player to easily compare multiple interpretations of the same piece. Here's an interactive  demo , and a video to give you a sense of how it works:" />

  <!-- Facebook -->
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://smus.com/classical-interpreters/" />
  <meta property="og:title" content="Comparing classical music interpretations" />
  <meta property="og:description" content="I built an audio player to easily compare multiple interpretations of the same piece. Here's an interactive  demo , and a video to give you a sense of how it works:" />

  <!-- Coil monetization experiment: https://coil.com/settings/monetize -->
  <meta name="monetization" content="$ilp.uphold.com/4Fnyw8KLaPZG">

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="180x180" href="/static/icons/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/static/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/static/icons/favicon-16x16.png">
  <link rel="manifest" href="/static/icons/site.webmanifest">

  <!-- Styles -->
  <link
  href='//fonts.googleapis.com/css?family=Roboto+Condensed:300|Open+Sans+Condensed:700|Source+Serif+Pro:400,700|Inconsolata' rel='stylesheet' type='text/css'>
  <link rel='stylesheet' href='/static/css/style.css'>
  <link rel='stylesheet' href='/static/css/syntax-highlight.css'>

  <!-- Feed -->
  <link href="https://smus.com/atom.xml" rel="alternate" title="Boris Smus" type="application/atom+xml"/>
</head>
<body>
<header>
  <div id='title'>
    <h1><a href='/'>Boris Smus</a></h1>
    <h2>interaction engineering</h2>
  </div>
  <nav role='navigation'>
    <a href='/about/' >About</a>
    <a href='/blog/' >Blog</a>
    <a href='/clippings/' >Clippings</a>
  </nav>
</header>

<section id='main'>
  <article>
    <a href='/classical-interpreters'><h1 class='title'>Comparing classical music interpretations</h1></a>
    <div class='body'>
      <p>I built an audio player to easily compare multiple interpretations of the same
piece. Here's an interactive <a href="https://borismus.github.io/classical-interpreter/">demo</a>, and a video to give you a sense of how it
works:</p>

<p><video src="/classical-interpreters/two-goulds.mp4" style="display: block; margin: 0 auto;" controls /></p>

<!--more-->

<h2>What does it mean to interpret classical music?</h2>

<p>At first glance, sheet music is prescriptive: the composer has provided all of
the notes, the dynamics (forte, piano), tempo (lento, presto) and changes in
tempo (de/accelerando).</p>

<p>In practice, however, the interpreter has a lot of leeway. In some extreme
cases, such as the <a href="https://en.wikipedia.org/wiki/Cadenza">Cadenza</a> in solo concertos, the performer gets to
improvize a melody based on a chord progression. Some pieces include
ornamentation (eg. trills, etc) which are largely left up to the performer to
interpret.</p>

<p>That said, cadenzas and ornaments are somewhat rare. In general, every piece is
under-specified by the composer. This gives the performer a lot of leeway to
express themselves through the performance, selecting tempo, phrasing,
articulation and tone.</p>

<h2>Example: Bach's Goldberg Variations</h2>

<p>The Goldberg Variations were composed by Johann Sebastian Bach in 1741, and then
popularized by Glenn Gould in his debut album in 1955, transforming a work once
considered esoteric into one of the most iconic piano recordings.</p>

<p>In 1981, a year before his death, Gould recorded the pieces again. After a long
period of reclusion, he was able to revisit the variations and produce a
completely different take. In an interview, he said:</p>

<blockquote>
  <p>...since I stopped playing concerts, about 20 years, having not played it in
  all that time, maybe I wasn't savaged by any over-exposure to it...</p>
</blockquote>

<h2>Compare Gould's 1955 and 1981 recordings</h2>

<p>Both the <a href="https://youtu.be/Cwas_7H5KUs?t=1m55s">1955</a> and <a href="https://www.youtube.com/watch?v=zpsfhTxo5yw&amp;t=173s">1981</a> recordings are available on YouTube, of course.
I found that listening to two distinct performances is not the same as having one
integrated player. So I built one: a player specifically for comparing multiple
interpretations of the same piece.</p>

<p>Here is a demo that lets you compare the first variation from the Goldberg
Variations. <a href="https://borismus.github.io/classical-interpreter/">Try it out here</a>. You can use your keyboard to skip between
interpretations (‚Üë, ‚Üì) just as easily as you can seek within a track (‚Üê, ‚Üí).
The mouse works as well. Note that I haven't tested at all on mobile. Sorry,
it's just a prototype and I'm on paternity leave üòá</p>

<h2>I also tried it on Mozart's Requiem</h2>

<p>I am a huge fan of Mozart's Requiem, and once came across an <a href="https://www.reddit.com/r/classicalmusic/comments/1xpqyh/what_is_the_best_recorded_performance_of_mozarts/">online thread
debating</a> which conductor's performance was the best. I soon
found myself listening to a dozen or so different versions of the same piece.
When I was a younger music appreciator, I would often wonder what the point of
a conductor <em>really</em> was. I no longer have this question.</p>

<p>Just to give you a taste for how different the interpretations are, here's an
example of three conductors performing the Introitus, the first movement in the
Requiem. <a href="https://borismus.github.io/classical-interpreter/?json=https://splendid-society.surge.sh/index.json">Check it out here</a>, but be patient as it may take a
minute to load and decode the audio. B√∂hm's brooding tempo and lumbering chorus
(ugh) contrasts especially well with Levin's crisp and minimalist take.</p>

<p><video src="/classical-interpreters/three-requiems.mp4" style="display: block; margin: 0 auto;" controls /></p>

<h2>Technical details</h2>

<p>For this prototype, I focused on creating a reasonable UI to play back and
interact with multiple time-aligned performances of the same piece. An <a href="https://borismus.github.io/classical-interpreter/goldberg/index.json">index
file</a> specifies metadata for each track, most importantly the URL to
the label file and the URL to the audio file. Each <a href="https://borismus.github.io/classical-interpreter/goldberg/gould-1955.txt">label file</a> is a
text file with lines in the format <code>START_TIME  END_TIME BAR_NUMBER</code>. </p>

<p>To create the label files, I manually annotated the waveform. Even with
Audacity's extremely useful <a href="https://manual.audacityteam.org/man/label_tracks.html">label track</a> feature, it was a lot
of manual work to go through the score, and find each bar's time
range in each recording. At the end of the day, I had start and end times for
each bar. For times that don't fall exactly on bar lines, I linearly interpolate
between the bar boundaries, which works reasonably well, but is sometimes a bit
off. More granular timing references would address this better, but that
currently means doing more manual labor. No thanks!</p>

<h3>Science, help me automate this, please</h3>

<p>An obvious question is how to automate the labor of synchronizing a recording to
a score. In general, I think this is an unsolved problem, especially for complex
tracks containing hundreds of instruments and varying levels of background
noise.</p>

<p>An promising approach that could work for solo piano music might be to use
something like <a href="https://magenta.tensorflow.org/onsets-frames">Onsets and Frames</a> to extract piano rolls and
then apply something like a Dynamic Time Warp (DTW) in piano roll space.  A more
general approach might be to synthesize each bar into raw audio (from MIDI), and
then align recordings to synthesized audio using something like DTW based on a
Constant-Q transform (CQT).</p>

<p>My brief and ill-guided attempts to <a href="https://musicinformationretrieval.com/dtw_example.html">do something like this</a> on real-world
examples didn't yield good enough results. Any ML/DSP experts want to take this
on?</p>

    </div>
    <div class='subfooter'>
      <div class='tombstone'>‚ñ™</div>
      <time class='published'>September 20, 2018</time>
    </div>
  </article>
</section>


<footer>
  <div>
    ¬© Copyright 2005‚Äì2022 Boris Smus.
  </div>
  <nav role="footer">
    <a href='https://smus.com/atom.xml'>RSS</a>

    <!-- Mastodon verification -->
    <a rel="me" href="https://mastodon.social/@borismus" style="display: none">Mastodon</a>
  </nav>
</footer>

<!-- Misc scripts: syntax highlighting, analytics, stats. -->
<script src="/static/js/highlight.pack.js"></script>
<script>
  // Syntax highlighting for code.
  hljs.tabReplace = '  ';
  hljs.initHighlightingOnLoad();
</script>
<script>
  // Google Analytics.
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-17930798-22', 'smus.com');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');
</script>
<script src="/lightning_error.js"></script>

</body>
</html>